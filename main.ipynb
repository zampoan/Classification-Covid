{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dir = \"covid-dataset\"\n",
    "class_names = ['COVID', 'Normal', 'Viral Pneumonia']\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# Make directories with each class name\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Train and test ratio\n",
    "split_ratio = 0.8\n",
    "covid_train_split = int(len(os.listdir(\"covid-dataset/COVID/images/\")) * split_ratio)\n",
    "normal_train_split = int(len(os.listdir(\"covid-dataset/Normal/images/\")) * split_ratio)\n",
    "pneumonia_train_split = int(len(os.listdir(\"covid-dataset/Viral Pneumonia/images/\")) * split_ratio)\n",
    "\n",
    "# Shuffle directories\n",
    "for class_name in class_names:\n",
    "    random.shuffle(os.listdir(dataset_dir + \"/\" + class_name + \"/images\"))\n",
    "\n",
    "# Move images into train and test\n",
    "covid_src_images = os.listdir(\"covid-dataset/COVID/images/\")\n",
    "train_covid_images = covid_src_images[:covid_train_split]\n",
    "test_covid_images = covid_src_images[covid_train_split:]\n",
    "for image in train_covid_images:\n",
    "    image_path = os.path.join(\"covid-dataset/COVID/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/train/COVID\")\n",
    "for image in test_covid_images:\n",
    "    image_path = os.path.join(\"covid-dataset/COVID/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/test/COVID\")\n",
    "\n",
    "normal_src_images = os.listdir(\"covid-dataset/Normal/images/\")\n",
    "train_normal_images = normal_src_images[:normal_train_split]\n",
    "test_normal_images = normal_src_images[normal_train_split:]\n",
    "for image in train_normal_images:\n",
    "    image_path = os.path.join(\"covid-dataset/Normal/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/train/Normal\")\n",
    "for image in test_normal_images:\n",
    "    image_path = os.path.join(\"covid-dataset/Normal/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/test/Normal\")\n",
    "\n",
    "pneumonia_src_images = os.listdir(\"covid-dataset/Viral Pneumonia/images/\")\n",
    "train_pneumonia_images = pneumonia_src_images[:pneumonia_train_split]\n",
    "test_pneumonia_images = pneumonia_src_images[pneumonia_train_split:]\n",
    "for image in train_pneumonia_images:\n",
    "    image_path = os.path.join(\"covid-dataset/Viral Pneumonia/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/train/Viral Pneumonia\")\n",
    "for image in test_pneumonia_images:\n",
    "    image_path = os.path.join(\"covid-dataset/Viral Pneumonia/images/\", image)\n",
    "    shutil.move(image_path, \"covid-dataset/test/Viral Pneumonia\")\n",
    "\n",
    "print(\"Files moved successfully!\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "BATCH_SIZE=32\n",
    "NUM_WORKERS=os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'Normal', 'Viral Pneumonia']\n",
      "Train data: Dataset ImageFolder\n",
      "    Number of datapoints: 12121\n",
      "    Root location: covid-dataset\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           ) \n",
      " Test data: Dataset ImageFolder\n",
      "    Number of datapoints: 3032\n",
      "    Root location: covid-dataset\\test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transforms)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=data_transforms)\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "print(f\"Train data: {train_data} \\n Test data: {test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Turn it into a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"scripts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/data_setup.py\n",
    "\"\"\"\n",
    "Putting data into Imagefolder and Dataloader\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "BATCH_SIZE=32\n",
    "NUM_WORKERS=os.cpu_count()\n",
    "\n",
    "def create_dataloaders(train_dir, test_dir, transform, batch_size, num_workers):\n",
    "    train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "    class_name = train_data.classes\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_data,batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model (CovidAid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CovidAidModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.covid_aid_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.covid_aid_7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.covid_aid_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.covid_aid_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.covid_aid_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.covid_aid_block_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.maxpool_2 = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(363, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.covid_aid_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_2(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_block_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_block_2(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_block_3(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_block_4(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.covid_aid_3(x)\n",
    "        x = self.covid_aid_4(x)\n",
    "        x = self.covid_aid_5(x)\n",
    "        x = self.covid_aid_6(x)\n",
    "        x = self.covid_aid_7(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 256, 256])\n",
      "torch.Size([32, 16, 128, 128])\n",
      "torch.Size([32, 32, 66, 66])\n",
      "torch.Size([32, 64, 35, 35])\n",
      "torch.Size([32, 128, 19, 19])\n",
      "torch.Size([32, 256, 11, 11])\n",
      "torch.Size([32, 512, 7, 7])\n",
      "torch.Size([32, 256, 9, 9])\n",
      "torch.Size([32, 128, 11, 11])\n",
      "torch.Size([32, 256, 11, 11])\n",
      "torch.Size([32, 3, 11, 11])\n",
      "torch.Size([32, 363])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4448, -0.1802,  0.3612],\n",
       "        [ 0.2820, -0.1401,  0.1586],\n",
       "        [ 0.4209, -0.6287, -0.2507],\n",
       "        [ 0.1778, -0.0448, -0.5364],\n",
       "        [ 0.0831, -0.1157, -0.0334],\n",
       "        [ 0.2719, -0.0613, -0.3318],\n",
       "        [ 0.4028, -0.1875, -0.3016],\n",
       "        [-0.0590,  0.1174, -0.3959],\n",
       "        [ 0.4976, -0.1635, -0.5833],\n",
       "        [ 0.3841, -0.3567,  0.2542],\n",
       "        [-0.2299,  0.0499, -0.4045],\n",
       "        [-0.2499, -0.3341,  0.2130],\n",
       "        [ 0.4143, -0.4366, -0.0422],\n",
       "        [ 0.0070,  0.1843, -0.2757],\n",
       "        [ 0.2843, -0.2930,  0.4217],\n",
       "        [ 0.2519, -0.5915, -0.0353],\n",
       "        [ 0.0359, -0.0201, -0.3710],\n",
       "        [-0.0137, -0.0333,  0.6405],\n",
       "        [ 0.0747, -0.2403, -0.0021],\n",
       "        [-0.1661, -0.4058, -0.1379],\n",
       "        [ 0.5806, -0.1805, -0.1671],\n",
       "        [-0.1874,  0.1722,  0.0017],\n",
       "        [ 0.2193, -0.0506, -0.5232],\n",
       "        [-0.1687, -0.1926,  0.1634],\n",
       "        [-0.0058, -0.2491, -0.1953],\n",
       "        [ 0.5129,  0.0940,  0.0367],\n",
       "        [ 0.0690, -0.1021, -0.2258],\n",
       "        [-0.1111,  0.0888,  0.3058],\n",
       "        [ 0.3515, -0.3150, -0.0374],\n",
       "        [ 0.2487, -0.4427, -0.1136],\n",
       "        [ 0.3083, -0.2129, -0.0418],\n",
       "        [ 0.2328, -0.3203, -0.3191]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = torch.rand(32,3,256,256)\n",
    "model = CovidAidModel()\n",
    "model(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.0\n"
     ]
    }
   ],
   "source": [
    "def conv_output_size(input_size, filter_size, stride, padding):\n",
    "    print((((input_size - filter_size + 2*padding)/stride)+1))\n",
    "\n",
    "conv_output_size(256, 3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 256])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m a \u001b[39m=\u001b[39m conv(test_img)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> 6\u001b[0m a \u001b[39m=\u001b[39m batch_norm(a)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Zheng Yao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Zheng Yao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input_dim(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[39m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Zheng Yao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:410\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_input_dim\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mexpected 4D input (got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mD input)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n",
      "\u001b[1;31mValueError\u001b[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "test_img = torch.rand(3,256,256)\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "batch_norm = nn.BatchNorm2d()\n",
    "a = conv(test_img)\n",
    "print(a.shape)\n",
    "a = batch_norm(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
